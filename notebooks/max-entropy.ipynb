{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0977e417-4bfe-4e9e-a24b-8f0a0a78fd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from scipy.linalg import null_space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86002d80-fc00-4904-a824-598bcbc41b0c",
   "metadata": {},
   "source": [
    "Goal: find the probability distribution $p = (p_1, \\ldots, p_6)$ which maximizes\n",
    "\n",
    "$$H(p) = -\\sum_i p_i \\log p_i$$\n",
    "\n",
    "subject to the constraints\n",
    "\n",
    "$$\\sum_i p_i = 1, \\quad \\sum_i i p_i = 4.5$$\n",
    "\n",
    "Interpretation: $p_i$ represents the probability that a six sided die is rolled and comes up with the pip $i$.\n",
    "The first constraint ensures that this is a probability distribution, and the second asserts that the average die roll is $4.5$.\n",
    "The objective function $H$ gives the entropy of the distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c695ba18-3e56-42d4-8b8e-4a33e2d22a87",
   "metadata": {},
   "source": [
    "Our strategy will be to run gradient descent along the (negative) entropy function, but there is a catch: most of the time gradient descent will pull us out of the space defined by the constraints.\n",
    "We will fix this by orthogonally projecting back onto the constraint space after reach step.\n",
    "\n",
    "Express the constraints as the matrix equation $Ax = b$ where:\n",
    "\n",
    "$$A = \\begin{pmatrix} 1 & 1 & 1 & 1 & 1 & 1 \\\\ 1 & 2 & 3 & 4 & 5 & 6 \\end{pmatrix}, \\quad b = \\begin{pmatrix} 1 \\\\ 4.5\\end{pmatrix}$$\n",
    "\n",
    "Let $L$ denote the solution space for the equation $Ax = b$; this is a 4-dimensional affine hyperplane in $\\mathbb{R}^6$.\n",
    "Our aim is to construct the map $P_L \\colon \\mathbb{R}^6 \\to \\mathbb{R}^6$ which orthogonally projects onto $L$.\n",
    "\n",
    "We start with the singular value decomposition of $A$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808bc004-2a3c-4843-a500-5888ff732dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.tensor([[1,1,1,1,1,1], [1,2,3,4,5,6]], dtype=float)\n",
    "b = torch.tensor([[1], [4.5]], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b0b3ef-d676-497a-b784-329776100347",
   "metadata": {},
   "outputs": [],
   "source": [
    "U, S, VT = torch.linalg.svd(A)\n",
    "V = torch.transpose(VT, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4713b159-74a3-4b7f-ba89-18d36d8dd062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick check that torch.linalg.svd works the way I think it does:\n",
    "S_matrix = torch.zeros(2, 6, dtype=float)\n",
    "S_matrix[:, :len(S)] = torch.diag(S)\n",
    "torch.linalg.multi_dot([U, S_matrix, VT])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb99454b-b3f9-4e2c-b412-58d576ff38af",
   "metadata": {},
   "source": [
    "The last `len(S)` columns of $V$ form an orthonormal basis for the kernel of $A$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2cde42-db98-42d1-a364-c5a38f12f43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = V[:, len(S):]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f730437-82e1-45c2-a62d-f2d558ae6282",
   "metadata": {},
   "source": [
    "The matrix $P = K K^T$ is the orthogonal projector onto the kernel of $A$.\n",
    "We can check this by verifying that $P^2 = P$ and that $AP = 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe534ef-2f90-4a5d-aa5e-d869d1d1f7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = torch.mm(K, torch.transpose(K, 0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cadf1a-fdb3-4037-9de2-a9509d9d6ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mm(P, P) - P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553b3914-bc1f-4c1f-9b4b-ff038a870cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mm(A, P)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fd9196-3e2c-48bb-b04e-bfbf375a523f",
   "metadata": {},
   "source": [
    "Finally, to construct the affine projector $P_L$ we just need to find any vector $v \\in L$ and then write:\n",
    "\n",
    "$$P_L x = v + P(x - v)$$\n",
    "\n",
    "(The easiest way to solve generic matrix equations in Pytorch appears to be `torch.linalg.lstsq`, which finds the least squares solution, but any other solution would work fine.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11f0c9b-6da3-4210-bc4f-c86dace30dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = torch.linalg.lstsq(A, b).solution\n",
    "v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f364c8-be77-4fe0-bb14-85861982c75e",
   "metadata": {},
   "source": [
    "Let's put all of this together into a Pytorch module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80417951-a8ab-48de-b52e-9724481660dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxEntropyDice(torch.nn.Module):\n",
    "    def __init__(self, num_faces, mean_constraint):\n",
    "        super().__init__()\n",
    "        self.num_faces = num_faces\n",
    "        self.mean_constraint = mean_constraint\n",
    "        self.kernel_projector, self.basepoint = self._compute_constraint_projector()\n",
    "        self.p = nn.Parameter(nn.functional.normalize(torch.rand(num_faces), p=1, dim=0))\n",
    "    \n",
    "    def forward(self):\n",
    "        entropy = -torch.sum(self.p * torch.log(self.p))\n",
    "        return entropy\n",
    "    \n",
    "    def enforce_constraint(self):\n",
    "        projected_p = self.basepoint + torch.mm(self.kernel_projector, self.p.reshape(len(self.p), 1) - self.basepoint)\n",
    "        self.p.copy_(projected_p.flatten())\n",
    "    \n",
    "    def _compute_constraint_projector(self):\n",
    "        probability_coeffs = torch.ones(self.num_faces)\n",
    "        mean_coeffs = torch.tensor(range(1, self.num_faces+1))\n",
    "        A = torch.stack((probability_coeffs, mean_coeffs))\n",
    "        b = torch.tensor([[1], [self.mean_constraint]])\n",
    "        \n",
    "        U, S, VT = torch.linalg.svd(A) # Singular value decomposition\n",
    "        V = torch.transpose(VT, 0, 1)\n",
    "        K = V[:, len(S):] # Orthonormal basis for kernel of A\n",
    "        \n",
    "        P = torch.mm(K, torch.transpose(K, 0, 1)) # Orthogonal projector onto the kernel of A\n",
    "        v = torch.linalg.lstsq(A, b).solution # A specific solution to Ax = b (the least squares solution)\n",
    "        return (P, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f63460-a994-4f4b-b0d2-cd9693ba14aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MaxEntropyDice(num_faces=6, mean_constraint=4.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9478fb9b-3300-4fee-88f0-7a25f6b01375",
   "metadata": {},
   "source": [
    "Now we return to the task of maximizing entropy using gradient descent, projecting back onto the constraints at each step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89a6111-0dda-45b1-bbc1-2c71c738b4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "for i in range(2000):\n",
    "    optimizer.zero_grad()\n",
    "    loss = -model() # Reverse the sign since the optimizer seeks a minimum\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.enforce_constraint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799950b4-3e18-4bca-bc95-590677361a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2820ea61-b42d-450a-97af-f186bcd31353",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
